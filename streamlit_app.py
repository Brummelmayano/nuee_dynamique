import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import plotly.graph_objects as go
import plotly.express as px

from sklearn.datasets import load_iris, load_wine
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

from nuees_dynamiques import (
    Nu√©esDynamique,
    compute_silhouette,
    compute_davies_bouldin,
    generate_synthetic_data,
    compute_distance_matrix,
)

# Mapping entre libell√©s fran√ßais descriptifs et valeurs internes
INIT_METHOD_LABELS = {
    "Centro√Øde unique (similaire KMeans)": "kmeans++",
    "Ensemble de points al√©atoires": "random",
    "Distribution probabiliste (GMM)": "gmm",
    "Axes factoriels (ACP)": "pca"
}

def compute_pca_cached(_X: np.ndarray, n_components: int):
    """PCA for etalon evolution."""
    pca = PCA(n_components=n_components)
    X_pca = pca.fit_transform(_X)
    return X_pca, pca

st.set_page_config(page_title="Nu√©es Dynamiques - Interactive Demo", page_icon="üöÄ", layout="wide")

st.title("üöÄ Nu√©es Dynamiques - Interactive Clustering Demo")
st.markdown(    
    "Ce petit d√©monstrateur interactif permet d'explorer la m√©thode des Nu√©es Dynamiques [Diday, E.(1971).](https://www.numdam.org/item/RSA_1971__19_2_19_0/)"
    )

st.markdown(
    """
    ### √Ä propos des noyaux multi-√©talons

    Le param√®tre **¬´ Nombre d'√©talons par cluster ¬ª** contr√¥le le nombre de points repr√©sentatifs par cluster :
    - **1 √©talon** : chaque cluster est repr√©sent√© par un seul point central (centro√Øde, m√©do√Øde, etc.).
    - **Plusieurs √©talons** : chaque cluster est repr√©sent√© par un **noyau** de plusieurs points repr√©sentatifs, permettant de capturer des formes de clusters allong√©es ou irr√©guli√®res.

    Lorsque **plusieurs √©talons** sont utilis√©s, les visualisations affichent tous les points du noyau sous forme de **marqueurs distinctifs**.

    Cette r√©alisation part du principe que l‚Äôon ne dispose pas d‚Äôindications sur la typologie probable, les √©talons sont donc initialement positionn√©s au hasard.

    """
    )

with st.expander("‚ÑπÔ∏è Guide des m√©thodes d'initialisation"):
    st.markdown("""
    ### M√©thodes d'initialisation disponibles

    | M√©thode | Type | Avantages | Cas d'usage | R√©f√©rence |
    |---------|------|-----------|-------------|-----------|
    | **Centro√Øde unique (similaire KMeans)** | Probabiliste | Convergence am√©lior√©e, 1 √©talon/cluster | Clusters sph√©riques, comportement K-Means | Arthur & Vassilvitskii 2007 |
    | **Ensemble de points al√©atoires** | Stochastique | Rapide, flexible (multi-√©talons) | Exploration, formes complexes | Diday 1971 |
    | **Distribution probabiliste (GMM)** | Probabiliste | Capture gaussiennes, haute pr√©cision | Clusters elliptiques, chevauchements | EM algorithm |
    | **Axes factoriels (ACP)** | D√©terministe | Exploite variance, reproductible | Donn√©es structur√©es, haute dimensionnalit√© | Su & Dy 2007 |

    **Recommandations scientifiques** :
    - **GMM** : Valid√© pour les clusters avec chevauchement et formes elliptiques (sup√©rieur √† K-means avec Jaccard 0.745 vs 0.652)
    - **ACP** : M√©thode PCA-Part (Su & Dy, 2007) g√©n√®re des clusters avec SSE proche du minimum global
    - **Centro√Øde unique** : Initialisation standard pour K-means, am√©liore la convergence
    - **Ensemble al√©atoire** : Baseline simple, n√©cessite plusieurs ex√©cutions pour robustesse

    **Distinction importante** :
    - **Initialisation** (`init_method`) : Choix des √©talons au D√âBUT de l'algorithme
    - **Calcul** (`etallon_method`) : Mise √† jour des √©talons √† CHAQUE IT√âRATION (centro√Øde, m√©do√Øde, m√©diane, mode)
    """)

# Sidebar controls
st.sidebar.header("‚öôÔ∏è Param√®tres du clustering")


# Algorithm selection (controls conditional UI)
algorithm = st.sidebar.radio("Algorithme", ["Nu√©es Dynamiques", "Comparer Nu√©es Dynamiques avec K-Means"])


# --- Dataset inputs (needed early to compute max_ni for the slider) ---
dataset_name = st.sidebar.selectbox("Dataset pr√©d√©fini", ["Iris", "Wine", "Synth√©tique"])
uploaded_file = st.sidebar.file_uploader("Importer un dataset (CSV)", type=["csv"], accept_multiple_files=False, help="Le fichier CSV doit contenir uniquement des donn√©es num√©riques.")


def load_dataset(name: str, n_clusters: int):
    """Charge un dataset selon le nom et retourne X, y_true, info dict."""
    info = {}
    if name == "Iris":
        X, y = load_iris(return_X_y=True)
        info["source"] = "Iris (sklearn)"
    elif name == "Wine":
        X, y = load_wine(return_X_y=True)
        info["source"] = "Wine (sklearn)"
    else:
        # Synth√©tique: use helper from the package
        X, y = generate_synthetic_data(n_samples=300, n_features=5, n_clusters=n_clusters, random_state=42)
        info["source"] = "Synth√©tique (generate_synthetic_data)"

    info["n_samples"] = X.shape[0]
    info["n_features"] = X.shape[1]
    info["n_clusters_expected"] = len(np.unique(y)) if y is not None else n_clusters
    return X, y, info


def load_custom_csv(uploaded_file):
    """Charge un fichier CSV personnalis√© et retourne X, y_true, info dict."""
    df = pd.read_csv(uploaded_file)
    X = df.select_dtypes(include=["number"]).values

    info = {}
    info["source"] = f"Personnalis√© (upload√©: {uploaded_file.name})"
    info["n_samples"] = X.shape[0]
    info["n_features"] = X.shape[1]
    info["n_clusters_expected"] = "D√©fini par l'utilisateur"

    return X, None, info


# Load a lightweight preview of the dataset early so we can compute a sensible max for the
# `n_etalons_per_cluster` slider (max_ni = n_samples // n_clusters). This allows validating
# the slider preventively and keeps backward compatibility when ni=1.
try:
    if uploaded_file is not None:
        X_preview, y_preview, info_preview = load_custom_csv(uploaded_file)
        # Reset file pointer for subsequent read in run_clustering block
        try:
            uploaded_file.seek(0)
        except Exception:
            pass
        dataset_name_preview = "Personnalis√©"
    else:
        X_preview, y_preview, info_preview = load_dataset(dataset_name, 3)
except Exception:
    X_preview, y_preview, info_preview = None, None, None



# Number of clusters - with input option
st.sidebar.subheader("Param√®tres de base")

n_clusters = st.sidebar.number_input("Nombre de clusters", min_value=2, max_value=100, value=3, step=1, help="Nombre de groupes √† identifier dans les donn√©es")

st.sidebar.subheader("M√©thode d'initialisation")
# Disable PCA if no preview available (to avoid invalid pca_n_components)
available_methods = ["random", "kmeans++", "gmm"]
if info_preview is not None:
    available_methods.append("pca")

# Create available labels based on available methods
available_labels = [label for label, method in INIT_METHOD_LABELS.items() if method in available_methods]

selected_label = st.sidebar.selectbox(
    "M√©thode d'initialisation des √©talons",
    available_labels,
    index=0,
    help="""
    **M√©thode d'initialisation des √©talons** : D√©termine comment les √©talons initiaux sont choisis au d√©but de l'algorithme.

    ‚Ä¢ Centro√Øde unique (similaire KMeans) : Initialisation probabiliste avec kmeans++ (Arthur & Vassilvitskii 2007), force 1 √©talon/cluster
    ‚Ä¢ Ensemble de points al√©atoires : S√©lection al√©atoire de k ensembles de points (Diday 1971, baseline)
    ‚Ä¢ Distribution probabiliste (GMM) : Mod√®le de m√©lange gaussien, capture les structures elliptiques
    ‚Ä¢ Axes factoriels (ACP) : Projection PCA et s√©lection des points extr√™mes (Su & Dy 2007, d√©terministe)

    ‚ö†Ô∏è √Ä ne pas confondre avec la "M√©thode de calcul de l'√©talon" qui d√©finit comment les √©talons sont MIS √Ä JOUR √† chaque it√©ration (centro√Øde, m√©do√Øde, etc.).
    """ + (" (ACP indisponible sans aper√ßu du dataset)" if "pca" not in available_methods else "")
)

# Map the selected label to the internal method
init_method = INIT_METHOD_LABELS[selected_label]

# Param√®tre ni : nombre d'√©talons par cluster (champ num√©rique dans la sidebar)
#noyaux multi-√©talons
if selected_label == "Centro√Øde unique (similaire KMeans)":
    n_etalons_per_cluster = 1
    st.sidebar.info("Mode centro√Øde unique activ√© : chaque cluster est repr√©sent√© par un seul point central (comme K-Means).")
else:
    if info_preview is not None:
        max_ni = max(1, info_preview.get("n_samples", 1) // max(1, 3))
        default_ni = min(30, max_ni)
    else:
        max_ni = 100
        default_ni = 30

    n_etalons_per_cluster = st.sidebar.number_input(
        "√âtalons par cluster",
        min_value=1,
        max_value=max_ni,
        value=min(default_ni, max_ni),
        step=1,
        help="Nombre de points repr√©sentatifs par cluster. 1 √©talon = forme simple, plusieurs √©talons = formes complexes ou allong√©es"
    )

# M√©thode d'√©talon visible uniquement lorsque ni == 1
if n_etalons_per_cluster == 1:
    etallon_method = st.sidebar.selectbox(
        "M√©thode de calcul de l'√©talon",
        ["centroid", "medoid", "median", "mode"],
        help="M√©thode de CALCUL de l'√©talon : d√©finit comment l'√©talon est mis √† jour √† chaque it√©ration (centro√Øde=moyenne, m√©do√Øde=point le plus central, etc.). Diff√©rent de l'initialisation."
    )
else:
    # Par d√©faut, centroid est utilis√© pour composer les noyaux multi-√©talons
    etallon_method = "centroid"

# Param√®tres conditionnels pour GMM
gmm_init_mode = "means"  # Valeur par d√©faut
if init_method == "gmm":
    gmm_init_mode = st.sidebar.radio(
        "Mode d'initialisation GMM",
        ["means", "sample"],
        index=0,
        help="""
        Mode d'initialisation pour le mod√®le de m√©lange gaussien :
        ‚Ä¢ means : Utilise les moyennes des composantes gaussiennes (stable, d√©terministe)
        ‚Ä¢ sample : √âchantillonne des points depuis les distributions gaussiennes (variable, stochastique)
        """
    )

# Param√®tres conditionnels pour PCA
pca_n_components = None  # Valeur par d√©faut (sera √©gal √† n_clusters)
if init_method == "pca" and info_preview is not None:
    # Calculer le nombre maximum de composantes (nombre de features)
    if info_preview is not None:
        max_components = info_preview.get("n_features", n_clusters)
    else:
        max_components = 10  # Valeur par d√©faut si pas de preview

    pca_n_components = st.sidebar.slider(
        "Nombre de composantes principales",
        min_value=1,
        max_value=max_components,
        value=min(n_clusters, max_components),
        step=1,
        help="""
        Nombre de composantes principales √† utiliser pour l'initialisation PCA.
        Plus de composantes = plus de points extr√™mes disponibles pour l'initialisation.
        Par d√©faut : √©gal au nombre de clusters.
        Recommandation : au moins n_clusters/2 pour √©viter l'initialisation al√©atoire de secours.
        """
    )

# Conditional parameter selectors based on algorithm choice
if algorithm == "Nu√©es Dynamiques":
    distance_metric = st.sidebar.selectbox("M√©trique de distance", ["euclidean", "manhattan", "minkowski", "chebyshev", "chi2", "sebestyen"])
    show_nd_params = True
else:  # Comparer Nu√©es Dynamiques avec K-Means
    st.sidebar.info("Affiche les r√©sultats ND et K-Means pour comparaison")
    distance_metric = st.sidebar.selectbox("M√©trique de distance", ["euclidean", "manhattan", "minkowski", "chebyshev", "chi2", "sebestyen"])
    show_nd_params = True

# Visualization dimension selector
viz_dim = st.sidebar.selectbox("Dimension de visualisation", ["2D", "3D"])

show_etalon_evolution = st.sidebar.checkbox(
    "Afficher l'√©volution des √©talons",
    value=False,
    help="Visualise la position des √©talons √† chaque it√©ration de l'algorithme."
)


# Run button remains at the end of the sidebar
run_button = st.sidebar.button("‚ñ∂Ô∏è Lancer l'analyse", type="primary")

def safe_metric(func, X, labels):
    try:
        return func(X, labels)
    except Exception:
        return None


def run_clustering(X, n_clusters, distance_metric, etallon_method, algorithm_name,
                   n_etalons_per_cluster=1, init_method="random",
                   gmm_init_mode="means", pca_n_components=None):
    results = {}

    if algorithm_name in ("Nu√©es Dynamiques", "Comparer Nu√©es Dynamiques avec K-Means"):
        try:
            nd = Nu√©esDynamique(
                data=X,
                n_clusters=n_clusters,
                distance_metric=distance_metric,
                init_method=init_method,  # Utiliser le param√®tre au lieu de "random"
                gmm_init_mode=gmm_init_mode,  # Nouveau param√®tre
                pca_n_components=pca_n_components,  # Nouveau param√®tre
                etallon_method=etallon_method,
                max_iterations=100,
                tolerance=1e-4,
                random_state=42,
                n_etalons_per_cluster=n_etalons_per_cluster,
            )
            nd.fit()

            # Apr√®s la ligne 199 (nd.fit())
            cluster_sizes = nd.get_cluster_sizes()
            homogeneite = nd.get_homogeneite_per_cluster()
            S_total = nd.get_S_total()
            rep_noyaux = nd.get_representative_noyaux()

            labels = nd.labels_
            centers = getattr(nd, "etallons_", None)
            inertia = None
            try:
                inertia = nd.get_inertia()
            except Exception:
                inertia = None

            silhouette = safe_metric(lambda X_arg, labels_arg: compute_silhouette(X_arg, labels_arg, metric=distance_metric), X, labels)
            davies_bouldin = safe_metric(compute_davies_bouldin, X, labels)

            results["Nu√©es Dynamiques"] = {
                "labels_": labels,
                "etallons_": centers,
                "n_iter_": getattr(nd, "n_iter_", None),
                "inertia": inertia,
                "silhouette": silhouette,
                "davies_bouldin": davies_bouldin,
                "nd": nd,
                # Nouvelles m√©triques de l'article
                "cluster_sizes": cluster_sizes,
                "homogeneite_per_cluster": homogeneite,
                "S_total": S_total,
                "representative_noyaux": rep_noyaux,
            }
        except Exception as exc:
            results["Nu√©es Dynamiques"] = {"error": str(exc)}

    if algorithm_name in ("Comparer Nu√©es Dynamiques avec K-Means",):
        try:
            km = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            km.fit(X)
            labels = km.labels_
            centers = km.cluster_centers_
            inertia = getattr(km, "inertia_", None)
            silhouette = safe_metric(compute_silhouette, X, labels)
            davies_bouldin = safe_metric(compute_davies_bouldin, X, labels)

            results["K-Means"] = {
                "labels_": labels,
                "etallons_": centers,
                "n_iter_": getattr(km, "n_iter_", None),
                "inertia": inertia,
                "silhouette": silhouette,
                "davies_bouldin": davies_bouldin,
            }
        except Exception as exc:
            results["K-Means"] = {"error": str(exc)}

    return results


def visualize_etalon_evolution(X_pca, pca, etallons_at_iter, labels, iteration, viz_dim):
    """Visualise les √©talons √† une it√©ration donn√©e."""
    explained = pca.explained_variance_ratio_.sum()

    if etallons_at_iter is None:
        st.warning(f"‚ö†Ô∏è √âtalons √† l'it√©ration {iteration} : Aucun historique disponible pour cette it√©ration.")
        return None

    # V√©rifier la forme des √©talons
    expected_features = pca.n_features_in_
    if etallons_at_iter.ndim == 2:
        if etallons_at_iter.shape[1] != expected_features:
            st.warning(f"‚ö†Ô∏è Forme inattendue √† l'it√©ration {iteration} : {etallons_at_iter.shape}, attendu (n_clusters, {expected_features})")
    elif etallons_at_iter.ndim == 3:
        if etallons_at_iter.shape[2] != expected_features:
            st.warning(f"‚ö†Ô∏è Forme inattendue √† l'it√©ration {iteration} : {etallons_at_iter.shape}, attendu (n_clusters, ni, {expected_features})")
    else:
        st.warning(f"‚ö†Ô∏è Dimension inattendue √† l'it√©ration {iteration} : {etallons_at_iter.ndim}D (attendu 2D ou 3D)")

    # Debug info (optionnel, √† commenter apr√®s r√©solution) :
    # st.write(f"üîç Debug iter {iteration} : shape={etallons_at_iter.shape}, ndim={etallons_at_iter.ndim}")

    center_label = "√âtalons"

    if viz_dim == "2D":
        fig, ax = plt.subplots(figsize=(10, 6))
        if labels is None:
            ax.text(0.5, 0.5, "No labels to display", ha="center")
            return fig

        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap="viridis", alpha=0.6, s=40)

        if etallons_at_iter is not None:
            try:
                if getattr(etallons_at_iter, "ndim", 2) == 2:
                    centers_pca = pca.transform(etallons_at_iter)
                    n_clusters_viz = etallons_at_iter.shape[0]
                    for k in range(n_clusters_viz):
                        color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                        darker_color = tuple(c * 0.7 for c in color[:3])
                        ax.scatter(
                            centers_pca[k, 0],
                            centers_pca[k, 1],
                            color=darker_color,
                            marker="X",
                            s=200,
                            edgecolors="black",
                            linewidths=2,
                            label=center_label if k == 0 else "",
                        )
                elif getattr(etallons_at_iter, "ndim", 2) == 3:
                    n_clusters_viz, ni, n_features = etallons_at_iter.shape
                    flat_centers = etallons_at_iter.reshape(-1, n_features)
                    centers_pca = pca.transform(flat_centers)
                    for k in range(n_clusters_viz):
                        start = k * ni
                        end = (k + 1) * ni
                        color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                        darker_color = tuple(c * 0.7 for c in color[:3])
                        ax.scatter(
                            centers_pca[start:end, 0],
                            centers_pca[start:end, 1],
                            color=darker_color,
                            marker="*",
                            s=100,
                            edgecolors="black",
                            linewidths=1,
                            label=f"{center_label} (noyaux, ni={ni})" if k == 0 else "",
                            alpha=0.8,
                        )
            except Exception as e:
                st.error(f"‚ö†Ô∏è Erreur affichage √©talons 2D (iter {iteration}) : {e}")

        cbar = fig.colorbar(scatter, ax=ax)
        ax.set_title(f"√âvolution des √©talons ‚Äî It√©ration {iteration} ‚Äî PCA 2D (var: {explained:.1%})")
        ax.set_xlabel("PC1")
        ax.set_ylabel("PC2")
        ax.grid(True, alpha=0.3)
        ax.legend()
        fig.tight_layout()

    else:  # 3D
        fig = go.Figure()

        if labels is None:
            fig.add_trace(go.Scatter3d(x=[0], y=[0], z=[0], mode='text', text=["No labels to display"]))
            return fig

        # Points de donn√©es
        fig.add_trace(go.Scatter3d(
            x=X_pca[:, 0],
            y=X_pca[:, 1],
            z=X_pca[:, 2],
            mode='markers',
            marker=dict(
                size=6,
                color=labels,
                colorscale='Viridis',
                opacity=0.6,
                showscale=True,
                colorbar=dict(
                    title="Cluster",
                    x=1.1,  # Position √† droite de la figure
                    y=0.5,  # Centr√© verticalement
                    len=0.6  # Longueur r√©duite pour √©viter le chevauchement
                )
            ),
            name="Donn√©es"
        ))

        if etallons_at_iter is not None:
            try:
                if getattr(etallons_at_iter, "ndim", 2) == 2:
                    centers_pca = pca.transform(etallons_at_iter)
                    n_clusters_viz = etallons_at_iter.shape[0]
                    colors = []
                    for k in range(n_clusters_viz):
                        color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                        darker = tuple(int(c * 0.7 * 255) for c in color[:3])
                        colors.append(f'rgb{darker}')
                    fig.add_trace(go.Scatter3d(
                        x=centers_pca[:, 0],
                        y=centers_pca[:, 1],
                        z=centers_pca[:, 2],
                        mode='markers',
                        marker=dict(
                            size=10,
                            color=colors,
                            symbol='x',
                            line=dict(width=2, color='black')
                        ),
                        name=center_label
                    ))
                elif getattr(etallons_at_iter, "ndim", 2) == 3:
                    n_clusters_viz, ni, n_features = etallons_at_iter.shape
                    flat_centers = etallons_at_iter.reshape(-1, n_features)
                    centers_pca = pca.transform(flat_centers)
                    colors = []
                    for k in range(n_clusters_viz):
                        color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                        darker = tuple(int(c * 0.7 * 255) for c in color[:3])
                        for _ in range(ni):
                            colors.append(f'rgb{darker}')
                    fig.add_trace(go.Scatter3d(
                        x=centers_pca[:, 0],
                        y=centers_pca[:, 1],
                        z=centers_pca[:, 2],
                        mode='markers',
                        marker=dict(
                            size=8,
                            color=colors,
                            symbol='diamond',
                            line=dict(width=1, color='black'),
                            opacity=0.8
                        ),
                        name=f"{center_label} (noyaux, ni={ni})"
                    ))
            except Exception as e:
                st.error(f"‚ö†Ô∏è Erreur affichage √©talons 3D (iter {iteration}) : {e}")

        fig.update_layout(
            title=f"√âvolution des √©talons ‚Äî It√©ration {iteration} ‚Äî PCA 3D (var: {explained:.1%})",
            scene=dict(
                xaxis_title="PC1",
                yaxis_title="PC2",
                zaxis_title="PC3"
            ),
            showlegend=True
        )

    return fig


def visualize_results(X, result: dict, algorithm_name: str, viz_dim: str):
    """Retourne une figure matplotlib avec la projection PCA 2D/3D et centres projet√©s."""
    n_components = 2 if viz_dim == "2D" else 3
    pca = PCA(n_components=n_components)
    X_pca = pca.fit_transform(X)
    explained = pca.explained_variance_ratio_.sum()

    # D√©terminer le label pour les centres
    center_label = "√âtalons" if algorithm_name == "Nu√©es Dynamiques" else "Centro√Ødes"

    if viz_dim == "2D":
        fig, ax = plt.subplots(figsize=(10, 6))
        labels = result.get("labels_")
        if labels is None:
            ax.text(0.5, 0.5, "No labels to display", ha="center")
            return fig

        scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap="viridis", alpha=0.6, s=40)

        centers = result.get("etallons_")
        if centers is not None:
            if centers.size == 0:
                st.info(f"‚ÑπÔ∏è Aucun centre √† afficher pour {algorithm_name}")
                centers = None  # Skip affichage
            else:
                try:
                    # Support both historical 2D etallons_ (n_clusters, n_features)
                    # and multi-noyaux 3D etallons_ (n_clusters, ni, n_features)
                    if getattr(centers, "ndim", 2) == 2:
                        centers_pca = pca.transform(centers)
                        n_clusters_viz = centers.shape[0]
                        for k in range(n_clusters_viz):
                            color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                            darker_color = tuple(c * 0.7 for c in color[:3])
                            ax.scatter(
                                centers_pca[k, 0],
                                centers_pca[k, 1],
                                color=darker_color,
                                marker="X",
                                s=200,
                                edgecolors="black",
                                linewidths=2,
                                label=center_label if k == 0 else "",
                            )
                    elif getattr(centers, "ndim", 2) == 3:
                        n_clusters_viz, ni, n_features = centers.shape
                        flat_centers = centers.reshape(-1, n_features)
                        centers_pca = pca.transform(flat_centers)
                        for k in range(n_clusters_viz):
                            start = k * ni
                            end = (k + 1) * ni
                            color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                            darker_color = tuple(c * 0.7 for c in color[:3])
                            ax.scatter(
                                centers_pca[start:end, 0],
                                centers_pca[start:end, 1],
                                color=darker_color,
                                marker="*",
                                s=100,
                                edgecolors="black",
                                linewidths=1,
                                label=f"{center_label} (noyaux, ni={ni})" if k == 0 else "",
                                alpha=0.8,
                            )
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erreur affichage centres 2D ({algorithm_name}) : {e}")

        cbar = fig.colorbar(scatter, ax=ax)
        ax.set_title(f"{algorithm_name} ‚Äî PCA 2D (var: {explained:.1%})")
        ax.set_xlabel("PC1")
        ax.set_ylabel("PC2")
        ax.grid(True, alpha=0.3)
        ax.legend()
        fig.tight_layout()

    else:  # 3D
        fig = go.Figure()

        labels = result.get("labels_")
        if labels is None:
            fig.add_trace(go.Scatter3d(x=[0], y=[0], z=[0], mode='text', text=["No labels to display"]))
            return fig

        # Points de donn√©es
        fig.add_trace(go.Scatter3d(
            x=X_pca[:, 0],
            y=X_pca[:, 1],
            z=X_pca[:, 2],
            mode='markers',
            marker=dict(
                size=6,
                color=labels,
                colorscale='Viridis',
                opacity=0.6,
                showscale=True,
                colorbar=dict(
                    title="Cluster",
                    x=1.1,  # Position √† droite de la figure
                    y=0.5,  # Centr√© verticalement
                    len=0.6  # Longueur r√©duite pour √©viter le chevauchement
                )
            ),
            name="Donn√©es"
        ))

        centers = result.get("etallons_")
        if centers is not None:
            if centers.size == 0:
                st.info(f"‚ÑπÔ∏è Aucun centre √† afficher pour {algorithm_name}")
                centers = None  # Skip affichage
            else:
                try:
                    if getattr(centers, "ndim", 2) == 2:
                        centers_pca = pca.transform(centers)
                        n_clusters_viz = centers.shape[0]
                        colors = []
                        for k in range(n_clusters_viz):
                            color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                            darker = tuple(int(c * 0.7 * 255) for c in color[:3])
                            colors.append(f'rgb{darker}')
                        fig.add_trace(go.Scatter3d(
                            x=centers_pca[:, 0],
                            y=centers_pca[:, 1],
                            z=centers_pca[:, 2],
                            mode='markers',
                            marker=dict(
                                size=10,
                                color=colors,
                                symbol='x',
                                line=dict(width=2, color='black'),
                                showscale=False  # D√©sactiver la colorbar pour les √©talons
                            ),
                            name=center_label
                        ))
                    elif getattr(centers, "ndim", 2) == 3:
                        n_clusters_viz, ni, n_features = centers.shape
                        flat_centers = centers.reshape(-1, n_features)
                        centers_pca = pca.transform(flat_centers)
                        colors = []
                        for k in range(n_clusters_viz):
                            color = plt.cm.viridis(k / max(1, n_clusters_viz - 1))
                            darker = tuple(int(c * 0.7 * 255) for c in color[:3])
                            for _ in range(ni):
                                colors.append(f'rgb{darker}')
                        fig.add_trace(go.Scatter3d(
                            x=centers_pca[:, 0],
                            y=centers_pca[:, 1],
                            z=centers_pca[:, 2],
                            mode='markers',
                            marker=dict(
                                size=8,
                                color=colors,
                                symbol='diamond',
                                line=dict(width=1, color='black'),
                                opacity=0.8
                            ),
                            name=f"{center_label} (noyaux, ni={ni})"
                        ))
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erreur affichage centres 3D ({algorithm_name}) : {e}")

        fig.update_layout(
            title=f"{algorithm_name} ‚Äî PCA 3D (var: {explained:.1%})",
            scene=dict(
                xaxis_title="PC1",
                yaxis_title="PC2",
                zaxis_title="PC3"
            ),
            showlegend=True
        )

    return fig


def display_article_metrics(X, res, n_clusters, distance_metric, silhouette=None, davies_bouldin=None):
    """Affiche les m√©triques conformes √† l'article pour Nu√©es Dynamiques."""
    cluster_sizes = res.get("cluster_sizes")
    homogeneite = res.get("homogeneite_per_cluster")
    S_total = res.get("S_total")
    rep_noyaux = res.get("representative_noyaux")
    inertia = res.get("inertia")
    
    if cluster_sizes is None or homogeneite is None or S_total is None or rep_noyaux is None:
        st.info("‚ÑπÔ∏è M√©triques de l'article non disponibles (mod√®le non entra√Æn√© ou erreur).")
        return
    
    st.subheader('üìä M√©triques de qualit√© du clustering (nu√©es dynamiques)')
    
    k = len(cluster_sizes)

    # V√©rifier coh√©rence avec les autres m√©triques
    if len(homogeneite) != k:
        st.warning(
            f"‚ö†Ô∏è Incoh√©rence des longueurs : cluster_sizes={k}, "
            f"homogeneite={len(homogeneite)}. "
            "Troncature aux longueurs communes."
        )
        min_len = min(k, len(homogeneite))
        k = min_len
        cluster_sizes = cluster_sizes[:min_len]
        homogeneite = homogeneite[:min_len]

    # R√©cup√©rer l'instance nd pour acc√©der aux √©talons complets
    nd = res.get("nd")
    if nd is None or not hasattr(nd, 'etallons_'):
        st.warning("‚ö†Ô∏è Instance Nu√©esDynamique non disponible pour afficher les √©talons.")
        return

    etallons = nd.etallons_

    # √âtape suppl√©mentaire pour aligner k avec le nombre d'√©talons disponibles
    n_clusters_etallons = etallons.shape[0]
    if n_clusters_etallons < k:
        k = n_clusters_etallons
        cluster_sizes = cluster_sizes[:k]
        homogeneite = homogeneite[:k]
        st.warning(f"‚ö†Ô∏è Nombre d'√©talons effectifs ({n_clusters_etallons}) inf√©rieur √† k ({k}). Troncature appliqu√©e.")

    # Cr√©er une colonne r√©sum√© pour les √©talons
    etalons_summary = []
    for i in range(k):
        if etallons.ndim == 2:  # ni=1, shape (n_clusters, n_features)
            n_etalons = 1
            coord_sample = etallons[i][:2] if etallons.shape[1] >= 2 else etallons[i]
        else:  # ni>1, shape (n_clusters, ni, n_features)
            n_etalons = etallons.shape[1]
            coord_sample = etallons[i, 0, :2] if etallons.shape[2] >= 2 else etallons[i, 0]

        # G√©rer les cas selon la longueur de coord_sample
        coord_len = len(coord_sample)
        if coord_len >= 2:
            summary = f"{n_etalons} pt(s) | Ex: [{coord_sample[0]:.2f}, {coord_sample[1]:.2f}...]"
        elif coord_len == 1:
            summary = f"{n_etalons} pt(s) | Ex: [{coord_sample[0]:.2f}...]"
        else:
            summary = f"{n_etalons} pt(s) | Ex: n/a"
        etalons_summary.append(summary)

    df_article = pd.DataFrame({
        'Cluster': range(1, k+1),  # Num√©rotation 1-based
        'Taille (nombre de points)': cluster_sizes,
        "L'homog√©n√©it√© de chacune des classes obtenues.": [f'{s:.3f}' for s in homogeneite],  # Pr√©cision √† 3 d√©cimales
        '√âtalons du noyau': etalons_summary
    })
    st.table(df_article)
    st.caption("**L'homog√©n√©it√©** : mesure la compacit√© des points autour des √©talons (valeur faible = cluster compact)")


    # Afficher toutes les m√©triques sur 4 colonnes
    st.markdown("**Indicateurs de performance :**")
    col1, col3, col4 = st.columns(3)
    col1.metric("La valeur de la partition obtenue.", f'{S_total:.3f}', help='Somme des dispersions intra-cluster (valeur faible = clustering compact)')

    col3.metric('Score de Silhouette', f'{silhouette:.3f}' if silhouette is not None else 'N/A', help='Coh√©sion interne et s√©paration des clusters (proche de 1 = excellent)')
    col4.metric('Indice Davies-Bouldin', f'{davies_bouldin:.3f}' if davies_bouldin is not None else 'N/A', help='Compacit√© relative et s√©paration (valeur faible = bon clustering)')
    st.caption('**Interpr√©tation** : Valeur de la partition (Inertie) faible  + Silhouette √©lev√©e + Davies-Bouldin faible = clustering optimal')
    


    # Ajouter des expanders pour afficher les √©talons complets par classe
    st.markdown("**D√©tail des √©talons par cluster :**")
    for i in range(k):
        if etallons.ndim == 2:  # ni=1
            etalons_i = etallons[i].reshape(1, -1)  # Reshape en (1, n_features) pour coh√©rence
        else:  # ni>1
            etalons_i = etallons[i]  # Shape (ni, n_features)
        
        with st.expander(f"Cluster {i+1} : D√©tails du noyau ({etalons_i.shape[0]} √©talons, {cluster_sizes[i]} points)"):
            df_etalons = pd.DataFrame(
                etalons_i,
                columns=[f'Dimension {j+1}' for j in range(etalons_i.shape[1])]
            )
            df_etalons.index = [f'√âtalon {j+1}' for j in range(etalons_i.shape[0])]
            st.dataframe(df_etalons.style.format("{:.4f}"))
            st.caption("√âtalons : points repr√©sentatifs centraux du cluster")
    
    # Expander optionnel pour la matrice R(x,i,L) sample
    with st.expander("Le degr√© de similarit√© de chaque individu √† chaque classe."):
        st.markdown(
            "**Distance minimale** de chaque observation aux √©talons de chaque cluster. "
            "Pour chaque point, on calcule la distance √† tous les √©talons du noyau d'un cluster, "
            "puis on retient la plus petite distance."
        )
        
        nd = res.get("nd")
        if nd is None or not hasattr(nd, 'etallons_'):
            st.warning("‚ö†Ô∏è Instance Nu√©esDynamique non disponible pour calculer R.")
            return
        
        n_samples_display = min(10, X.shape[0])

        # Validation de coh√©rence entre n_clusters param√®tre et n_clusters du mod√®le
        n_clusters_model = getattr(nd.etallons_, 'shape', (0,))[0]
        if n_clusters_model != n_clusters:
            n_clusters_eff = min(n_clusters, n_clusters_model)
            st.warning(f"‚ö†Ô∏è Incoh√©rence entre n_clusters param√®tre ({n_clusters}) et n_clusters du mod√®le ({n_clusters_model}). Utilisation de {n_clusters_eff} clusters effectifs (min({n_clusters}, {n_clusters_model})).")
        else:
            n_clusters_eff = n_clusters

        if n_clusters_eff == 0:
            st.warning("Aucun cluster valide pour matrice R.")
            return

        R_sample = np.zeros((n_samples_display, n_clusters_eff))

        for i in range(n_clusters_eff):
            noyau_i = nd.etallons_[i]  # shape: (ni, n_features) ou (n_features,) si ni=1
            # G√©rer le cas o√π noyau_i est 1D (ni=1)
            if noyau_i.ndim == 1:
                noyau_i = noyau_i.reshape(1, -1)
            
            # Calculer distances entre les 10 premiers points et le noyau i
            dists_i = compute_distance_matrix(X[:n_samples_display], noyau_i, distance_metric)
            # Prendre le minimum sur l'axe des √©talons (axis=1)
            R_sample[:, i] = np.min(dists_i, axis=1)
        
        df_R = pd.DataFrame(R_sample, columns=[f'Distance au cluster {i+1}' for i in range(n_clusters_eff)])
        df_R.index = [f'Observation {i+1}' for i in range(n_samples_display)]
        st.dataframe(df_R.style.format("{:.4f}"))


if run_button:
    # Load dataset
    with st.spinner("Chargement du dataset..."):
        try:
            if uploaded_file is not None:
                X, y_true, info = load_custom_csv(uploaded_file)
                dataset_name = "Personnalis√©"
            else:
                X, y_true, info = load_dataset(dataset_name, n_clusters)
        except Exception as exc:
            st.error(f"Erreur lors du chargement du dataset: {exc}")
            st.stop()

    st.subheader("Informations du dataset")
    st.write(info)

    # Check for invalid dataset
    if X.size == 0:
        st.error("Le dataset ne contient pas de donn√©es num√©riques valides.")
        st.stop()
    if np.any(np.isnan(X)):
        st.error("Le dataset contient des valeurs NaN. Veuillez nettoyer les donn√©es.")
        st.stop()

    # Avertissement pour chi2 avec valeurs n√©gatives
    if distance_metric == "chi2" and np.any(X < 0):
        st.warning(
            "‚ö†Ô∏è **Distance œá¬≤ sensible aux valeurs n√©gatives** : Votre dataset contient des valeurs n√©gatives. "
            "La distance œá¬≤ est optimale pour des donn√©es non-n√©gatives (ex: histogrammes, fr√©quences). "
            "Consid√©rez normaliser vos donn√©es (min-max scaling vers [0,1]) ou choisir une autre m√©trique."
        )

    # Run clustering
    with st.spinner("Ex√©cution du clustering..."):
        results = run_clustering(
            X, n_clusters, distance_metric, etallon_method, algorithm,
            n_etalons_per_cluster=n_etalons_per_cluster,
            init_method=init_method,  # Nouveau param√®tre
            gmm_init_mode=gmm_init_mode,  # Nouveau param√®tre
            pca_n_components=pca_n_components  # Nouveau param√®tre
        )

    # Display results
    if algorithm == "Comparer Nu√©es Dynamiques avec K-Means":
        st.info(
            "‚ö†Ô∏è **Note sur les m√©triques d'√©valuation** : Le score de Silhouette pour Nu√©es Dynamiques "
            "utilise la m√©trique de distance s√©lectionn√©e. Cependant, K-Means et l'indice Davies-Bouldin "
            "utilisent toujours la distance Euclidienne (limitation de scikit-learn)."
        )
        col1, col2 = st.columns(2)
        names = ["Nu√©es Dynamiques", "K-Means"]
        for col, name in zip((col1, col2), names):
            col.header(name)
            res = results.get(name, {})
            if "error" in res:
                col.error(res["error"])
                continue

            inertia = res.get("inertia")
            silhouette = res.get("silhouette")
            davies_bouldin = res.get("davies_bouldin")
            n_iter = res.get("n_iter_")

            col.info(f"It√©rations : {n_iter}")
            fig = visualize_results(X, res, name, viz_dim)
            if viz_dim == "3D":
                col.plotly_chart(fig, use_container_width=True)
            else:
                col.pyplot(fig)


            # Afficher les m√©triques uniquement pour K-Means (Nu√©es Dynamiques les affiche dans display_article_metrics)
            if name == "K-Means":
                m1, m2, m3 = col.columns(3)
                m1.metric("Inertia", f"{inertia:.2f}" if inertia is not None else "N/A")
                m2.metric("Silhouette", f"{silhouette:.3f}" if silhouette is not None else "N/A")
                m3.metric("Davies-Bouldin", f"{davies_bouldin:.3f}" if davies_bouldin is not None else "N/A")

            # Apr√®s l'affichage de la visualisation (ligne 653)
            if name == "Nu√©es Dynamiques":
                display_article_metrics(X, res, n_clusters, distance_metric, silhouette, davies_bouldin)

    else:
        name = algorithm
        res = results.get(name, {})
        if "error" in res:
            st.error(res["error"])
        else:
            st.subheader(name)
            inertia = res.get("inertia")
            silhouette = res.get("silhouette")
            davies_bouldin = res.get("davies_bouldin")
            n_iter = res.get("n_iter_")

            # Les m√©triques seront affich√©es dans display_article_metrics pour Nu√©es Dynamiques
            # (pas d'affichage ici pour √©viter la duplication)

            st.info(f"It√©rations : {n_iter}")
            fig = visualize_results(X, res, name, viz_dim)
            if viz_dim == "3D":
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.pyplot(fig)
            # Apr√®s la ligne 677 (st.pyplot(fig))
            if name == "Nu√©es Dynamiques":
                display_article_metrics(X, res, n_clusters, distance_metric, silhouette, davies_bouldin)

    # Persister les r√©sultats pour acc√®s hors du bloc run_button
    st.session_state['clustering_results'] = {
        'results': results,
        'X': X,
        'y_true': y_true,
        'viz_dim': viz_dim,
        'n_clusters': n_clusters,
        'distance_metric': distance_metric,
        'dataset_name': dataset_name,
        'algorithm': algorithm
    }

# Section √©volution des √©talons (persistante, hors du bloc run_button)
if 'clustering_results' in st.session_state and show_etalon_evolution:
    data = st.session_state['clustering_results']
    results = data['results']
    X = data['X']
    viz_dim = data['viz_dim']
    st.caption("‚ÑπÔ∏è La dimension de visualisation est li√©e au dernier run de clustering.")
    
    if "Nu√©es Dynamiques" in results:
        nd = results.get("Nu√©es Dynamiques", {}).get("nd")
        if nd and hasattr(nd, 'etallons_history_') and len(nd.etallons_history_) > 1:
            st.info(f"üìä Historique disponible : {len(nd.etallons_history_)} √©tats (it√©rations 0 √† {len(nd.etallons_history_)-1})")
            
            # V√©rifier coh√©rence avec n_iter_
            if nd.n_iter_ is not None and isinstance(nd.n_iter_, int):
                expected_len = nd.n_iter_ + 1
                if len(nd.etallons_history_) != expected_len:
                    st.warning(f"‚ö†Ô∏è Incoh√©rence : historique a {len(nd.etallons_history_)} √©tats, attendu {expected_len} (n_iter_+1)")
            else:
                st.info("‚ÑπÔ∏è n_iter_ non disponible, v√©rification de coh√©rence ignor√©e.")
            
            # PCA computation (no caching to handle varying shapes)
            n_components = 2 if viz_dim == "2D" else 3
            pca = PCA(n_components=n_components)
            X_pca = pca.fit_transform(X)
            
            st.subheader("üìà √âvolution des √©talons √† travers les it√©rations")
            iteration = st.slider(
                "It√©ration de l'algorithme",
                min_value=0,
                max_value=len(nd.etallons_history_) - 1,
                value=0,
                step=1,
                key="etalon_iteration_slider"  # Cl√© stable
            )
            
            if iteration >= len(nd.etallons_history_):
                st.error(f"‚ùå Index {iteration} hors limites (historique : {len(nd.etallons_history_)} √©tats)")
            else:
                etallons_at_iter = nd.etallons_history_[iteration]
                labels = results["Nu√©es Dynamiques"]["labels_"]
                fig = visualize_etalon_evolution(X_pca, pca, etallons_at_iter, labels, iteration, viz_dim)
                
                if fig is None:
                    st.info("‚ÑπÔ∏è Aucune figure √† afficher pour cette it√©ration.")
                else:
                    if viz_dim == "3D":
                        st.plotly_chart(fig, use_container_width=True, key="etalon_evolution")  # Cl√© stable sans {iteration}
                    else:
                        st.pyplot(fig)
        else:
            st.info("L'historique des √©talons n'est pas disponible ou l'algorithme a converg√© imm√©diatement.")


# Utiliser session_state si disponible (apr√®s clustering), sinon skip
if 'clustering_results' in st.session_state:
    # Download dataset with labels
    st.subheader("üì• T√©l√©charger les r√©sultats")
    data = st.session_state['clustering_results']
    results = data['results']
    X = data['X']
    y_true = data['y_true']
    algorithm = data['algorithm']
    distance_metric = data['distance_metric']
    
    if algorithm == "Comparer Nu√©es Dynamiques avec K-Means":
        # For the compare option, download ND results by default
        name = "Nu√©es Dynamiques"
        res = results.get(name, {})
        labels = res.get("labels_")
    else:
        res = results.get(algorithm, {})
        labels = res.get("labels_")
    
    if labels is not None:
        df_download = pd.DataFrame(X)
        df_download[f"cluster_{algorithm}"] = labels
        # If the Nu√©es Dynamiques result contains multi-noyaux (3D etallons_), compute the
        # index (0..ni-1) of the closest point within the assigned kernel for each sample.
        res_et = res.get("etallons_")
        if res_et is not None and getattr(res_et, "ndim", 2) == 3:
            n_samples_dl = X.shape[0]
            n_clusters_dl, ni_dl, n_features_dl = res_et.shape
            closest_indices = np.zeros(n_samples_dl, dtype=int)
            # Vectorized computation: group samples by cluster_id, compute distances once per cluster
            unique_clusters = np.unique(labels)
            for cluster_id in unique_clusters:
                cluster_mask = labels == cluster_id
                X_cluster = X[cluster_mask]  # samples in this cluster
                noyau = res_et[int(cluster_id)]  # shape (ni, n_features)
                # compute distances between cluster samples and noyau points
                dists = compute_distance_matrix(X_cluster, noyau, metric=distance_metric)
                # find argmin for each sample within the noyau
                closest_per_sample = np.argmin(dists, axis=1)
                closest_indices[cluster_mask] = closest_per_sample
            df_download["closest_noyau_idx"] = closest_indices

        if y_true is not None:
            df_download["true_label"] = y_true

        csv_data = df_download.to_csv(index=False)
        st.download_button(
            label="üìä T√©l√©charger le dataset avec les labels de clustering (CSV)",
            data=csv_data,
            file_name=f"dataset_clustered_{algorithm.replace(' ', '_')}.csv",
            mime="text/csv",
        )


if 'clustering_results' in st.session_state:
    st.markdown("---")
    st.subheader("Aper√ßu du dataset")
    data = st.session_state['clustering_results']
    X = data['X']
    y_true = data['y_true']
    df_preview = pd.DataFrame(X)
    if y_true is not None:
        df_preview["true_label"] = y_true
    st.dataframe(df_preview.head(20))



st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #888; font-size: 0.9em;'>"
    "<p><strong>Nu√©es Dynamiques - D√©monstrateur Clustering Interactif</strong></p>"
    "<p>Universit√© de Kinshasa</p>"
    "<p>R√©alis√© par Brummel Duasenge Mayano</p>"
    "</div>",
    unsafe_allow_html=True
)
